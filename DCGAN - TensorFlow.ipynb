{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3N1h8mZWLba"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "#import dask.array as da    \n",
    "import time\n",
    "import keras\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_df = pd.read_csv(\"final_data_path.csv\")\n",
    "data_path_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_df['faces'][0][0:19] + '_data' +  data_path_df['faces'][0][19:] + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lms_data = {}\n",
    "faces_data = {}\n",
    "\n",
    "for i in range (0, len(data_path_df)):\n",
    "    count = 0\n",
    "    count1 = 0\n",
    "    basepath = Path('lms_data' +  data_path_df['faces'][i][19:] + '/')\n",
    "    basepath1 = Path('faces_data' +  data_path_df['faces'][i][19:] + '/')\n",
    "    files_in_basepath = basepath.iterdir()\n",
    "    for item in files_in_basepath:\n",
    "        count = count + 1\n",
    "    count1 = int(np.round(0.9*count, decimals = 0))\n",
    "    files_in_basepath = basepath.iterdir()\n",
    "    for item in files_in_basepath:            \n",
    "        if (count1 > 0):\n",
    "            item = str(item)\n",
    "            lms_data.setdefault('train', []).append(item)\n",
    "            count1 = count1 - 1\n",
    "            files_in_basepath1 = basepath1.iterdir()    \n",
    "            for item1 in files_in_basepath1:\n",
    "                item1 = str(item1)\n",
    "                faces_data[item] = item1\n",
    "                break\n",
    "        else:\n",
    "            item = str(item)\n",
    "            lms_data.setdefault('test', []).append(item)\n",
    "            files_in_basepath1 = basepath1.iterdir()    \n",
    "            for item1 in files_in_basepath1:\n",
    "                item1 = str(item1)\n",
    "                faces_data[item] = item1\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = list(faces_data.keys())\n",
    "random.shuffle(final_data)\n",
    "train_data = final_data[0:int(np.round((0.8 * len(final_data)), decimals = 0))]\n",
    "test_data = final_data[int(np.round((0.8 * len(final_data)), decimals = 0)):]\n",
    "print(np.shape(train_data))\n",
    "print(np.shape(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    #inshape = (64, 1000, 64)\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=(1000,64), strides = 2))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Conv1D(128, kernel_size=3, activation='relu', strides = 2))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "       # model.add(tf.keras.layers.Conv1D(824, kernel_size=3, activation='relu', strides = 2))\n",
    "        #model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Conv1D(512, kernel_size=3, activation='relu', strides = 2))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Conv1D(256, kernel_size=3, activation='relu', strides = 2))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', strides = 2))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.AveragePooling1D(pool_size = 2))\n",
    "        model.add(tf.keras.layers.AveragePooling1D(pool_size = 2))\n",
    "        model.add(tf.keras.layers.AveragePooling1D(pool_size = 2))\n",
    "        model.add(tf.keras.layers.AveragePooling1D(pool_size = 2))\n",
    "        #model.add(tf.keras.layers.AveragePooling1D(pool_size = 2))\n",
    "        #model.add(tf.keras.layers.AveragePooling1D(pool_size = 2))\n",
    "\n",
    "        model.add(tf.keras.layers.Reshape((1, 1, 64)))\n",
    "\n",
    "        model.add(tfa.layers.SpectralNormalization(tf.keras.layers.Conv2DTranspose(512, (4, 4), strides=(1, 1), activation='relu')))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tfa.layers.SpectralNormalization(tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding = 'same', activation='relu')))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tfa.layers.SpectralNormalization(tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding = 'same', activation='relu')))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tfa.layers.SpectralNormalization(tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding = 'same', activation='relu')))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tfa.layers.SpectralNormalization(tf.keras.layers.Conv2DTranspose(16, (3, 3), strides=(2, 2), padding = 'same', activation='relu')))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tfa.layers.SpectralNormalization(tf.keras.layers.Conv2DTranspose(3, (3, 3), strides=(2, 2), padding = 'same', activation='tanh')))\n",
    "        #model.add(tf.keras.layers.Conv2DTranspose(3, (3, 3), strides=(2, 2), padding = 'same', activation='relu'))  \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPfXQGviW0as",
    "outputId": "2d7900d2-6f9b-44cb-cf07-8f9274641161"
   },
   "outputs": [],
   "source": [
    "generator = generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAQRDeZjW0dQ"
   },
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(16, (4, 4), strides=(1, 1), input_shape=[128, 128, 3]))\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(tfa.layers.SpectralNormalization(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2))))\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(tfa.layers.SpectralNormalization(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2))))\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(tfa.layers.SpectralNormalization(tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2))))\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(tfa.layers.SpectralNormalization(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2))))\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(tfa.layers.SpectralNormalization(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2))))\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWudg5ImW0fj",
    "outputId": "3f122036-b6ee-4e42-bb35-1451c43afdd7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discriminator = discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TyDf0RWW0iE"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def D_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.fill(np.shape(real_output), 0.9), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "  \n",
    "def G_loss(fake_output):\n",
    "    loss =  cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWkyDd6lW0kk"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDLiQZUqW9jU"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images1, images2):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(images1, training=True)        \n",
    "        real_output = discriminator((images2+0.01*tf.random.uniform(shape=[images2.shape[0],128,128,3], minval=-1, maxval=1, dtype=tf.float64)), training=True)\n",
    "        fake_output = discriminator((generated_images+0.01*tf.random.uniform(shape=[generated_images.shape[0],128,128,3], minval=-1, maxval=1, dtype=tf.float32)), training=True)\n",
    "\n",
    "        gen_loss = G_loss(fake_output)\n",
    "        disc_loss = D_loss(real_output, fake_output)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "        \n",
    "        return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-bUoDnzW9l7"
   },
   "outputs": [],
   "source": [
    "def sv_img(model, epoch, test_input):\n",
    "    img_list = []\n",
    "    img = np.load(test_input[random.randrange(0, 29871)])\n",
    "    img = cv2.resize(img, dsize=(64, 1000))\n",
    "    img = (img-127.5)/127.5\n",
    "    img_list.append(img)\n",
    "    img_array = np.array(img_list)\n",
    "    prediction = model(img_array, training=False)\n",
    "    prediction = (prediction[0]*127.5)+127.5\n",
    "    prediction = prediction.numpy()\n",
    "    plt.imshow(prediction.astype('uint8'))\n",
    "    #plt.savefig('/data/raghav/generated_images/generated_img{}.png'.format(epoch), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gen_loss_final = []\n",
    "disc_loss_final = []\n",
    "loss = []\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    for i in range(0, 1867):\n",
    "        data1 = []\n",
    "        data2 = []\n",
    "        count = 0\n",
    "        for img in train_data[64*i:]:\n",
    "            if (count < 64):\n",
    "                data1 = list(data1)\n",
    "                data2 = list(data2)\n",
    "                lms = np.load(img)\n",
    "                lms = cv2.resize(lms, dsize=(64, 1000))\n",
    "                lms = (lms-127.5)/127.5\n",
    "                data1.append(lms)\n",
    "                data1 = np.array(data1)\n",
    "                data2.append(cv2.imread(faces_data[img])[:,:,::-1])\n",
    "                data2 = np.array(data2)\n",
    "                data2 = (data2-127.5)/127.5\n",
    "                count = count + 1\n",
    "            else:\n",
    "                break\n",
    "        loss.append(train_step(data1, data2))\n",
    "    print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    gen_loss_final.append(sum(loss[0]))\n",
    "    disc_loss_final.append(sum(loss[1]))\n",
    "    loss = []\n",
    "    sv_img(generator, epoch + 1, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(gen_loss_final, label = 'Generator loss')\n",
    "plt.plot(disc_loss_final, label = 'Discriminator loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled18.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
