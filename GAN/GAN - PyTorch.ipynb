{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import os, shutil\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import sys, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c041688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "number_of_gpus = torch.cuda.device_count()\n",
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\ragha\\Documents\\NVIDIA Internship\\final_data_path.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lms_data = {}\n",
    "faces_data = {}\n",
    "\n",
    "for i in range (0, len(df)):\n",
    "    count = 0\n",
    "    count1 = 0\n",
    "    basepath = Path('lms_data' +  df['faces'][i][19:] + '/')\n",
    "    basepath1 = Path('faces_data' +  df['faces'][i][19:] + '/')\n",
    "    files_in_basepath = basepath.iterdir()\n",
    "    for item in files_in_basepath:            \n",
    "        item = str(item)\n",
    "        files_in_basepath1 = basepath1.iterdir()    \n",
    "        for item1 in files_in_basepath1:\n",
    "            item1 = str(item1)\n",
    "            faces_data[item] = item1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = list(faces_data.items())\n",
    "random.shuffle(final_data)\n",
    "#train_data = final_data[0: int(0.7999 * len(final_data))]\n",
    "#val_data = final_data[int(0.7999 * len(final_data)): int(np.round((0.8 * len(final_data)), decimals = 0))]\n",
    "#test_data = final_data[int(np.round((0.8 * len(final_data)), decimals = 0)): ]\n",
    "train_data = final_data[ : -25]\n",
    "val_data = final_data[-25: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lms = np.array(train_data)[:, 0]\n",
    "train_faces = np.array(train_data)[:, 1]\n",
    "val_lms = np.array(val_data)[:, 0]\n",
    "val_faces = np.array(val_data)[:, 1]\n",
    "#test_lms = np.array(test_data)[:, 0]\n",
    "#test_faces = np.array(test_data)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total dataset size -\", len(final_data))\n",
    "print(\"Train size -\", len(train_data))\n",
    "print(\"Validation size -\", len(val_data))\n",
    "#print(\"Test size -\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.lms = train_lms\n",
    "        self.faces = train_faces\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.faces)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lms_path = train_lms[idx]\n",
    "        faces_path = train_faces[idx]\n",
    "        img1 = np.load(lms_path, allow_pickle=True)\n",
    "        img1 = cv2.resize(img1, dsize=(64, 1000))\n",
    "        img1 = (img1-127.5)/127.5\n",
    "        img2 = cv2.imread(faces_path)[:,:,::-1]\n",
    "        img2 = (img2-127.5)/127.5\n",
    "        img1_tensor = torch.from_numpy(img1)\n",
    "        img2_tensor = torch.from_numpy(img2)\n",
    "        img1_tensor = img1_tensor.view(64, 1000)\n",
    "        img2_tensor = img2_tensor.view(3, 128, 128)\n",
    "        \n",
    "        return img1_tensor.float(), img2_tensor.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = Dataset()\n",
    "data_loader1 = DataLoader(dataset1, batch_size=64, shuffle=False, pin_memory=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393fc055",
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, labels in data_loader1:\n",
    "    print(\"Batch of images has shape: \",imgs.shape)\n",
    "    print(\"Batch of labels has shape: \", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd28df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e86db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1=nn.Conv1d(64,64,3,stride=2)\n",
    "        self.bn1=nn.BatchNorm1d(64)\n",
    "        self.relu=nn.LeakyReLU()\n",
    "        self.conv2=nn.Conv1d(64,128,3,stride=2)\n",
    "        self.bn2=nn.BatchNorm1d(128)\n",
    "        self.conv3=nn.Conv1d(128,512,3,stride=2)\n",
    "        self.bn3=nn.BatchNorm1d(512)\n",
    "        self.conv4=nn.Conv1d(512,256,3,stride=2)\n",
    "        self.bn4=nn.BatchNorm1d(256)\n",
    "        self.conv5=nn.Conv1d(256,64,3,stride=2)\n",
    "        self.bn5=nn.BatchNorm1d(64)\n",
    "        self.pool1=nn.AvgPool1d(2)\n",
    "        self.pool2=nn.AvgPool1d(2)\n",
    "        self.pool3=nn.AvgPool1d(2)\n",
    "        self.pool4=nn.AvgPool1d(2)\n",
    "        \n",
    "        self.deconv1=nn.utils.parametrizations.spectral_norm(nn.ConvTranspose2d(64,512,4,stride = 1))\n",
    "        self.bn6=nn.BatchNorm2d(512)\n",
    "        self.deconv2=nn.utils.parametrizations.spectral_norm(nn.ConvTranspose2d(512,256,4,stride=2,padding=1))\n",
    "        self.bn7=nn.BatchNorm2d(256)\n",
    "        self.deconv3=nn.utils.parametrizations.spectral_norm(nn.ConvTranspose2d(256,128,4,stride=2,padding=1))\n",
    "        self.bn8=nn.BatchNorm2d(128)\n",
    "        self.deconv4=nn.utils.parametrizations.spectral_norm(nn.ConvTranspose2d(128,64,4,stride=2,padding=1))\n",
    "        self.bn9=nn.BatchNorm2d(64)\n",
    "        self.deconv5=nn.utils.parametrizations.spectral_norm(nn.ConvTranspose2d(64,16,4,stride=2,padding=1))\n",
    "        self.bn10=nn.BatchNorm2d(16)\n",
    "        self.deconv6=nn.utils.parametrizations.spectral_norm(nn.ConvTranspose2d(16,3,4,stride=2,padding=1))\n",
    "        self.bn11=nn.BatchNorm2d(3)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #batch_size=x.size()[0]\n",
    "        #x = x.view(-1, 64, 1000)\n",
    "        x=self.relu(self.bn1(self.conv1(x)))\n",
    "        x=self.relu(self.bn2(self.conv2(x)))\n",
    "        x=self.relu(self.bn3(self.conv3(x)))\n",
    "        x=self.relu(self.bn4(self.conv4(x)))\n",
    "        x=self.relu(self.bn5(self.conv5(x)))\n",
    "        x=self.pool1(x)\n",
    "        x=self.pool2(x)\n",
    "        x=self.pool3(x)\n",
    "        x=self.pool4(x)\n",
    "        \n",
    "        x=x.view(-1,64,1,1)\n",
    "        \n",
    "        x=self.relu(self.bn6(self.deconv1(x)))\n",
    "        x=self.relu(self.bn7(self.deconv2(x)))\n",
    "        x=self.relu(self.bn8(self.deconv3(x)))\n",
    "        x=self.relu(self.bn9(self.deconv4(x)))\n",
    "        x=self.relu(self.bn10(self.deconv5(x)))\n",
    "        x=self.tanh(self.bn11(self.deconv6(x)))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa92d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gen = Generator().to(device)\n",
    "\n",
    "if (device.type == 'cuda') and (number_of_gpus > 1):\n",
    "    gen = nn.DataParallel(gen, list(range(number_of_gpus)))\n",
    "\n",
    "gen.apply(weights_init)\n",
    "\n",
    "summary(gen, (64, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1=nn.Conv2d(3,16,4)\n",
    "        self.bn1=nn.BatchNorm2d(16)\n",
    "        self.relu=nn.LeakyReLU()\n",
    "        self.conv2=nn.utils.parametrizations.spectral_norm(nn.Conv2d(16,64,3,stride=2))\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.conv3=nn.utils.parametrizations.spectral_norm(nn.Conv2d(64,128,3,stride=2))\n",
    "        self.bn3=nn.BatchNorm2d(128)\n",
    "        self.conv4=nn.utils.parametrizations.spectral_norm(nn.Conv2d(128,256,3,stride=2))\n",
    "        self.bn4=nn.BatchNorm2d(256)\n",
    "        self.conv5=nn.utils.parametrizations.spectral_norm(nn.Conv2d(256,64,3,stride=2))\n",
    "        self.bn5=nn.BatchNorm2d(64)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1=nn.Linear(2304, 1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x=self.relu(self.bn1(self.conv1(x)))\n",
    "        x=self.relu(self.bn2(self.conv2(x)))\n",
    "        x=self.relu(self.bn3(self.conv3(x)))\n",
    "        x=self.relu(self.bn4(self.conv4(x)))\n",
    "        x=self.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.flat(x)\n",
    "        x=self.sigmoid(self.fc1(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator().to(device)\n",
    "\n",
    "if (device.type == 'cuda') and (number_of_gpus > 1):\n",
    "    disc = nn.DataParallel(disc, list(range(number_of_gpus)))\n",
    "\n",
    "disc.apply(weights_init)\n",
    "\n",
    "summary(disc, (3,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac88679",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss().to(device)\n",
    "gen_optim=torch.optim.Adam(gen.parameters(), lr=0.0002)\n",
    "disc_optim=torch.optim.Adam(disc.parameters(), lr=0.00015)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(disc_optim, step_size = 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d26c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.lms = val_lms\n",
    "        self.faces = val_faces\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.faces)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lms_path = val_lms[idx]\n",
    "        faces_path = val_faces[idx]\n",
    "        img1 = np.load(lms_path, allow_pickle=True)\n",
    "        img1 = cv2.resize(img1, dsize=(64, 1000))\n",
    "        img1 = (img1-127.5)/127.5\n",
    "        img2 = cv2.imread(faces_path)[:,:,::-1]\n",
    "        img2 = (img2-127.5)/127.5\n",
    "        img1_tensor = torch.from_numpy(img1)\n",
    "        img2_tensor = torch.from_numpy(img2)\n",
    "        img1_tensor = img1_tensor.view(64, 1000)\n",
    "        img2_tensor = img2_tensor.view(3, 128, 128)\n",
    "        \n",
    "        return img1_tensor.float(), img2_tensor.float()\n",
    "    \n",
    "dataset2 = Dataset()\n",
    "data_loader2 = DataLoader(dataset2, batch_size=25, shuffle=False, pin_memory=True) \n",
    "\n",
    "def val_testing(model, epoch):\n",
    "\n",
    "    fake_imgs = []\n",
    "    x = 0\n",
    "    y = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_x, batch_y in data_loader2:\n",
    "            \n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            prediction = model(batch_x).detach().cpu()\n",
    "            prediction = (prediction*127.5)+127.5  \n",
    "            grid_img = torchvision.utils.make_grid(prediction, nrow=5, normalize = True)\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(grid_img.permute(1, 2, 0))\n",
    "            plt.show()\n",
    "            #plt.savefig(r'C:/Users/ragha/Documents/NVIDIA Internship/generated_images/generated_img{}.png'.format(epoch), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab07317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    img_list = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    iters = 0\n",
    "    fake_label = 0.0 \n",
    "    num_epochs = 1000\n",
    "    count = 0\n",
    "    final_gen_loss = []\n",
    "    final_disc_loss = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        count = count+1\n",
    "        for batch_x, batch_y in data_loader1:\n",
    "            \n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            disc.zero_grad()\n",
    "            real_data = batch_y.to(device)\n",
    "            batch_size = real_data.size(0)\n",
    "            noise = (0.01 - 0.00) * torch.rand(batch_size, 3, 128, 128) + 0.00\n",
    "            noise = noise.to(device)\n",
    "            real_data = real_data + noise\n",
    "            label = (1.11 - 0.9) * torch.rand(batch_size) + 0.9\n",
    "            label = label.to(device)\n",
    "            output = disc(real_data).view(-1)\n",
    "            disc_err_real = criterion(output, label)\n",
    "            disc_err_real.backward()\n",
    "            \n",
    "            noise = (0.01 - 0.00) * torch.rand(batch_size, 64, 1000) + 0.00\n",
    "            noise = noise.to(device)\n",
    "            batch_x = batch_x + noise\n",
    "            fake = gen(batch_x)\n",
    "            noise = (0.01 - 0.00) * torch.rand(batch_size, 3, 128, 128) + 0.00\n",
    "            noise = noise.to(device)\n",
    "            fake = fake + noise\n",
    "            label.fill_(fake_label)\n",
    "            label = label.to(device)\n",
    "            output = disc(fake.detach()).view(-1)\n",
    "            disc_err_fake = criterion(output, label)\n",
    "            disc_err_fake.backward()\n",
    "            disc_err = disc_err_real + disc_err_fake\n",
    "            disc_optim.step()\n",
    "\n",
    "            gen.zero_grad()\n",
    "            label = (1.3 - 0.7) * torch.rand(batch_size) + 0.7\n",
    "            label = label.to(device)\n",
    "            output = disc(fake).view(-1)\n",
    "            gen_err = criterion(output, label)\n",
    "            gen_err.backward()\n",
    "            gen_optim.step()\n",
    "\n",
    "            G_losses.append(gen_err.item())\n",
    "            D_losses.append(disc_err.item())\n",
    "                        \n",
    "            \n",
    "        final_gen_loss.append(sum(G_losses)/len(G_losses))\n",
    "        final_disc_loss.append(sum(D_losses)/len(D_losses))                            \n",
    "\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time-start_time\n",
    "\n",
    "        print(\"Time taken:\", time_taken, \"seconds\")\n",
    "        print(\"Epoch: \", epoch+1)\n",
    "        print('Loss_D: %.4f \\tLoss_G: %.4f' % (final_disc_loss[-1], final_gen_loss[-1]))\n",
    "        val_testing(gen, count)\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'gen_state_dict': gen.state_dict(),\n",
    "            'gen_optimizer_state_dict': gen_optim.state_dict(),\n",
    "            'gen_loss': G_losses[-1],\n",
    "            }, 'C:/Users/ragha/Documents/NVIDIA Internship/generator_model.pt')\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'disc_state_dict': disc.state_dict(),\n",
    "            'disc_optimizer_state_dict': disc_optim.state_dict(),\n",
    "            'disc_loss': D_losses[-1],\n",
    "            }, 'C:/Users/ragha/Documents/NVIDIA Internship/discriminator_model.pt')\n",
    "        \n",
    "        G_losses = []\n",
    "        D_losses = []\n",
    "        \n",
    "    return final_gen_loss, final_disc_loss\n",
    "\n",
    "        \n",
    "loss1, loss2 = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a2244",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss1)\n",
    "plt.plot(loss2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ffa2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211709f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
